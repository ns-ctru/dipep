##### Pre-Categorised Continuous Variables

```{r results_lasso_categorical, echo = FALSE, cache = FALSE, warning = FALSE, message = FALSE, results = 'hide', eval = TRUE}
predictor <- c(categorical, common)
lasso.categorical <- dipep_glmnet_orig(df          = dipep,
                                       classification = classification,
                                       predictor      = predictor,
                                       alpha          = 1,
                                       model          = 'LASSO : Pre-Categorised Variables',
                                       exclude        = NULL,
                                       exclude.non.recruited = TRUE,
                                       exclude.dvt           = TRUE,
                                       exclude.anti.coag     = FALSE,
                                       exclude.missing       = TRUE,
                                       legend                = TRUE,
                                       threshold             = 0.3)

```



```{r results_lasso_categorical_plot, echo = FALSE, cache = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 10, results = 'asis', eval = TRUE}
## Plot the change in coefficients over time
lasso.categorical$lasso.plot + guides(colour = FALSE)

```

###### Cross-Validation

[Leave One Out Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation) has been utilised internally at each step of the fitting of the LASSO to shrink the point estimate and inform the next iteration.  The model should not be over-fitted though and this can be achieved by considering the parameter Lambda and either taking the minimum value or the value corresponding 1 x SE of the point-estimate of the Mean Squared Error, which are the dashed lines on the following graph.

<!--- Partial explanation at http://stats.stackexchange.com/questions/77546/how-to-interpret-glmnet --->

```{r results_lasso_categorical_cross_validation_plot, echo = FALSE, cache = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 10, results = 'asis', eval = TRUE}
lasso.categorical$lasso.cv.plot

```

###### Sensitivity and Specificity

Having selected an optimal value for Lambda the predicted probabilities are then obtained and ROC curves plotted along with the calculated Area Under the Curve (AUC) statistic.  A cut-point for probability can be chosen but in the absence of any choice a default of `p = 0.5` has been used for now in order to calculate the various performance metrics.

```{r results_lasso_categorical_roc, echo = FALSE, cache = FALSE, warning = FALSE, message = FALSE,  fig.width = 10,fig.height = 10, results = 'markup', eval = TRUE}
lasso.categorical$lasso.cv.roc
lasso.categorical$lasso.cv.summary.stats %>%
    kable(caption = 'AUC for Cross-Validated LASSO for varying Lambda thresholds.')
lasso.categorical$lasso.cv.coef.lambda %>%
    kable(caption = 'Coefficients for Lambda thresholds.')

```

The question naturally arises as to whether a parsimonious model with less variables from an earlier stage in the LASSO can be used without losing predictive ability of the model.  It is self-evident that simpler models will have poorer predictive value because they use less information in order to make the prediction, but in order to provide a visual overview and numerical quantification of the trade-off between complexity and predictive value *all* steps from the LASSO are plotted as ROC curves and goodness of fit statistics have been calculated for each sequential step.


```{r results_lasso_categorical_roc_all, echo = FALSE, cache = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 10, results = 'asis', eval = TRUE}
lasso.categorical$lasso.cv.roc.all
lasso.categorical$lasso.cv.summary.stats.all %>%
    kable(caption = paste0('Predictive statistics for sequential steps of LASSO using a cut-point of p = ',
                           lasso.categorical$threshold,
                           '.'))

```

```{r results_lasso_categorical_roc_animate, echo = FALSE, cache = FALSE, warning = FALSE, message = FALSE, fig.show = 'animate', eval = FALSE}
## Animation of ROC curve
ani.record(reset = TRUE)
par(bg = 'white')
for(i in seq(1:length(lasso.categorical$lasso.cv$lambda))){
    t <- dplyr::filter(lasso.categorical$lasso.cv.predicted, term == i) %>%
         ggplot(aes(d = D, m = M)) +
         geom_roc() +
         ggtitle(paste0('ROC Curves for LASSO step ', i)) +
        style_roc() + theme_bw()
    print(t)
    ani.record()
}
oopts = ani.options(interval = 0.5)
ani.replay()
rm(t)

```
