@article{hosmer1997,
    abstract = {{
                Recent work has shown that there may be disadvantages in the use of the chi-square-like goodness-of-fit tests for the logistic regression model proposed by Hosmer and Lemeshow that use fixed groups of the estimated probabilities. A particular concern with these grouping strategies based on estimated probabilities, fitted values, is that groups may contain subjects with widely different values of the covariates. It is possible to demonstrate situations where one set of fixed groups shows the model fits while the test rejects fit using a different set of fixed groups. We compare the performance by simulation of these tests to tests based on smoothed residuals proposed by le Cessie and Van Houwelingen and Royston, a score test for an extended logistic regression model proposed by Stukel, the Pearson chi-square and the unweighted residual sum-of-squares. These simulations demonstrate that all but one of Royston's tests have the correct size. An examination of the performance of the tests when the correct model has a quadratic term but a model containing only the linear term has been fit shows that the Pearson chi-square, the unweighted sum-of-squares, the Hosmer-Lemeshow decile of risk, the smoothed residual sum-of-squares and Stukel's score test, have power exceeding 50 per cent to detect moderate departures from linearity when the sample size is 100 and have power over 90 per cent for these same alternatives for samples of size 500. All tests had no power when the correct model had an interaction between a dichotomous and continuous covariate but only the continuous covariate model was fit. Power to detect an incorrectly specified link was poor for samples of size 100. For samples of size 500 Stukel's score test had the best power but it only exceeded 50 per cent to detect an asymmetric link function. The power of the unweighted sum-of-squares test to detect an incorrectly specified link function was slightly less than Stukel's score test. We illustrate the tests within the context of a model for factors associated with low birth weight.
            }},
    author = {Hosmer, D. W. and Hosmer, T. and Le Cessie, S. and Lemeshow, S.},
    citeulike-article-id = {9960110},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/9160492},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=9160492},
    day = {15},
    issn = {0277-6715},
    journal = {Statistics in medicine},
    keywords = {goodnessoffit, staistics},
    month = may,
    number = {9},
    pages = {965--980},
    pmid = {9160492},
    posted-at = {2013-09-06 11:05:15},
    priority = {2},
    title = {{A comparison of goodness-of-fit tests for the logistic regression model.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/9160492},
    volume = {16},
    year = {1997}
}

@Manual{R,
    title        = {R: A Language and Environment for Statistical
                    Computing},
    author       = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address      = {Vienna, Austria},
    year         = 2012,
    note         = {{ISBN} 3-900051-07-0},
    url          = {http://www.R-project.org}
}

@book{harrell2006,
    abstract = {{There are many books that are excellent sources of knowledge about individual stastical tools (survival models, general linear models, etc.), but the art of data analysis is about choosing and using multiple tools. In the words of Chatfield "...students typically know the technical details of regressin for example, but not necessarily when and how to apply it. This argues the need for a better balance in the literature and in statistical teaching between techniques and problem solving strategies." Whether analyzing risk factors, adjusting for biases in observational studies, or developing predictive models, there are common problems that few regression texts address. For example, there are missing data in the majority of datasets one is likely to encounter (other than those used in textbooks!) but most regression texts do not include methods for dealing with such data effectively, and texts on missing data do not cover regression modeling.}},
    author = {Harrell, F. E.},
    citeulike-article-id = {788274},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387952322},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387952322},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/45820971},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387952322},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387952322},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387952322/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387952322},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387952322},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387952322},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387952322\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387952322},
    day = {10},
    edition = {Corrected},
    howpublished = {Hardcover},
    isbn = {0387952322},
    keywords = {book, books, modelling, regression, regression\_modelling\_strategies, statistics, survival},
    month = jan,
    posted-at = {2009-12-08 10:54:37},
    priority = {2},
    publisher = {Springer},
    title = {{Regression Modeling Strategies}},
    url = {http://www.worldcat.org/isbn/0387952322},
    year = {2001}
}

@article{hosmer1980,
    abstract = {{Several test statistics are proposed for the purpose of assessing the goodness of fit of the multiple logistic regression model. The test statistics are obtained by applying a chi-square test for a contingency table in which the expected frequencies are determined using two different grouping strategies and two different sets of distributional assumptions. The null distributions of these statistics are examined by applying the theory for chi-square tests of Moore Spruill (1975) and through computer simulations. All statistics are shown to have a chi-square distribution or a distribution which can be well approximated by a chi-square. The degrees of freedom are shown to depend on the particular statistic and the distributional assumptions. The power of each of the proposed statistics is examined for the normal, linear, and exponential alternative models using computer simulations.}},
    author = {Hosmer, D. W. and Lemeshow, S.},
    citeulike-article-id = {9011509},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/03610928008827941},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/03610928008827941},
    day = {1},
    doi = {10.1080/03610928008827941},
    journal = {Communications in Statistics - Theory and Methods},
    keywords = {fit, logistic, modelling, regression},
    month = jan,
    number = {10},
    pages = {1043--1069},
    posted-at = {2013-10-21 16:03:57},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{Goodness of fit tests for the multiple logistic regression model}},
    url = {http://dx.doi.org/10.1080/03610928008827941},
    volume = {9},
    year = {1980}
}

@article{burnham2004,
    abstract = {{The model selection literature has been generally poor at reflecting the deep foundations of the Akaike information criterion (AIC) and at making appropriate comparisons to the Bayesian information criterion (BIC). There is a clear philosophy, a sound criterion based in information theory, and a rigorous statistical foundation for AIC. AIC can be justified as Bayesian using a  ” savvy” prior on models that is a function of sample size and the number of model parameters. Furthermore, BIC can be derived as a non-Bayesian result. Therefore, arguments about using AIC versus BIC for model selection cannot be from a Bayes versus frequentist perspective. The philosophical context of what is assumed about reality, approximating models, and the intent of model-based inference should determine whether AIC or BIC is used. Various facets of such multimodel inference are presented here, particularly methods of model averaging.}},
    author = {Burnham, K. P. and Anderson, D. R.},
    citeulike-article-id = {11258},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0049124104268644},
    citeulike-linkout-1 = {http://smr.sagepub.com/content/33/2/261.abstract},
    citeulike-linkout-2 = {http://smr.sagepub.com/content/33/2/261.full.pdf},
    citeulike-linkout-3 = {http://smr.sagepub.com/cgi/content/abstract/33/2/261},
    citeulike-linkout-4 = {http://www.ingentaconnect.com/content/sage/j221/2004/00000033/00000002/art00004},
    day = {01},
    doi = {10.1177/0049124104268644},
    issn = {1552-8294},
    journal = {Sociological Methods \& Research},
    keywords = {aic, bic, modelling, statistics},
    month = nov,
    number = {2},
    pages = {261--304},
    posted-at = {2013-12-04 09:07:51},
    priority = {2},
    publisher = {SAGE Publications},
    title = {{Multimodel Inference}},
    url = {http://dx.doi.org/10.1177/0049124104268644},
    volume = {33},
    year = {2004}
}

@article{akaike1974,
    abstract = {{The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples.}},
    author = {Akaike, H.},
    citeulike-article-id = {849862},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tac.1974.1100705},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1100705},
    day = {06},
    doi = {10.1109/tac.1974.1100705},
    institution = {Institute of Statistical Mathematics, Minato-ku, Tokyo, Japan},
    issn = {0018-9286},
    journal = {Automatic Control, IEEE Transactions on},
    keywords = {aic, modelling, statistics},
    month = dec,
    number = {6},
    pages = {716--723},
    posted-at = {2013-12-04 09:02:28},
    priority = {2},
    publisher = {IEEE},
    title = {{A new look at the statistical model identification}},
    url = {http://dx.doi.org/10.1109/tac.1974.1100705},
    volume = {19},
    year = {1974}
}

@article{schwarz1978,
    author = {Schwarz, G.},
    citeulike-article-id = {4239466},
    citeulike-linkout-0 = {http://dx.doi.org/10.1214/aos/1176344136},
    doi = {10.1214/aos/1176344136},
    issn = {0090-5364},
    journal = {The Annals of Statistics},
    keywords = {bic, modelling, statistics},
    month = mar,
    number = {2},
    pages = {461--464},
    posted-at = {2013-12-04 09:06:30},
    priority = {2},
    title = {{Estimating the Dimension of a Model}},
    url = {http://dx.doi.org/10.1214/aos/1176344136},
    volume = {6},
    year = {1978}
}

@article{lijmer1999,
    abstract = {{The literature contains a large number of potential biases in the evaluation of diagnostic tests. Strict application of appropriate methodological criteria would invalidate the clinical application of most study results. To empirically determine the quantitative effect of study design shortcomings on estimates of diagnostic accuracy. Observational study of the methodological features of 184 original studies evaluating 218 diagnostic tests. Meta-analyses on diagnostic tests were identified through a systematic search of the literature using MEDLINE, EMBASE, and DARE databases and the Cochrane Library (1996-1997). Associations between study characteristics and estimates of diagnostic accuracy were evaluated with a regression model. Relative diagnostic odds ratio (RDOR), which compared the diagnostic odds ratios of studies of a given test that lacked a particular methodological feature with those without the corresponding shortcomings in design. Fifteen (6.8\%) of 218 evaluations met all 8 criteria; 64 (30\%) met 6 or more. Studies evaluating tests in a diseased population and a separate control group overestimated the diagnostic performance compared with studies that used a clinical population (RDOR, 3.0; 95\% confidence interval [CI], 2.0-4.5). Studies in which different reference tests were used for positive and negative results of the test under study overestimated the diagnostic performance compared with studies using a single reference test for all patients (RDOR, 2.2; 95\% CI, 1.5-3.3). Diagnostic performance was also overestimated when the reference test was interpreted with knowledge of the test result (RDOR, 1.3; 95\% CI, 1.0-1.9), when no criteria for the test were described (RDOR, 1.7; 95\% CI, 1.1-2.5), and when no description of the population under study was provided (RDOR, 1.4; 95\% CI, 1.1-1.7). These data provide empirical evidence that diagnostic studies with methodological shortcomings may overestimate the accuracy of a diagnostic test, particularly those including nonrepresentative patients or applying different reference standards.}},
    author = {Lijmer, J. G. and Mol, B. W. and Heisterkamp, S. and Bonsel, G. J. and Prins, M. H. and van der Meulen, J. H. and Bossuyt, P. M.},
    citeulike-article-id = {5968986},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/10493205},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=10493205},
    day = {15},
    issn = {0098-7484},
    journal = {JAMA},
    keywords = {bias, diagnostic\_test, statistics, studydesign},
    month = sep,
    number = {11},
    pages = {1061--1066},
    pmid = {10493205},
    posted-at = {2014-09-18 14:58:12},
    priority = {2},
    title = {{Empirical evidence of design-related bias in studies of diagnostic tests.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/10493205},
    volume = {282},
    year = {1999}
}

@article{altman1989,
    abstract = {{We describe a bootstrap investigation of the stability of a Cox proportional hazards regression model resulting from the analysis of a clinical trial of azathioprine versus placebo in patients with primary biliary cirrhosis. We have considered stability to refer both to the choice of variables included in the model and, more importantly, to the predictive ability of the model. In stepwise Cox regression analyses of 100 bootstrap samples using 17 candidate variables, the most frequently selected variables were those selected in the original analysis, and no other important variable was identified. Thus there was no reason to doubt the model obtained in the original analysis. For each patient in the trial, bootstrap confidence intervals were constructed for the estimated probability of surviving two years. It is shown graphically that these intervals are markedly wider than those obtained from the original model.}},
    address = {Medical Statistics Laboratory, Imperial Cancer Research Fund, PO Box 123, Lincoln's Inn Fields, London WC2A 3PX, U.K.; Statistical Research Unit, Blegdamsvej 3, 2200 Copenhagen N, Denmark},
    author = {Altman, D. G. and Andersen, P. K.},
    citeulike-article-id = {6129934},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780080702},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/113396466/ABSTRACT},
    doi = {10.1002/sim.4780080702},
    issn = {02776715},
    journal = {Statistics in Medicine},
    keywords = {cox, modelling, ph, regression, statistics, stepwise},
    month = jul,
    number = {7},
    pages = {771--783},
    posted-at = {2009-11-17 15:18:49},
    priority = {2},
    publisher = {Wiley Subscription Services, Inc., A Wiley Company},
    title = {{Bootstrap investigation of the stability of a cox regression model}},
    url = {http://dx.doi.org/10.1002/sim.4780080702},
    volume = {8},
    year = {1989}
}

@article{copas1983,
    abstract = {{The fit of a regression predictor to new data is nearly always worse than its fit to the original data. Anticipating this shrinkage leads to Stein-type predictors which, under certain assumptions, give a uniformly lower prediction mean squared error than least squares. Shrinkage can be particularly marked when stepwise fitting is used: the shrinkage is then closer to that expected of the full regression rather than of the subset regression actually fitted. Preshrunk predictors for selected subsets are proposed and tested on a number of practical examples. Both multiple and binary (logistic) regression models are considered.}},
    author = {Copas, J. B.},
    citeulike-article-id = {5333705},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2345402},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2345402},
    doi = {10.2307/2345402},
    issn = {00359246},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {methodology, problems, statisics, stepwise},
    number = {3},
    pages = {311--354},
    posted-at = {2010-05-26 10:22:26},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {{Regression, Prediction and Shrinkage}},
    url = {http://dx.doi.org/10.2307/2345402},
    volume = {45},
    year = {1983}
}

@article{Tibshirani1996,
    abstract = {{We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.}},
    author = {Tibshirani, R.},
    citeulike-article-id = {2453666},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2346178},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2346178},
    doi = {10.2307/2346178},
    issn = {00359246},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {inflation, methodology, problems, statistics, stepwise},
    number = {1},
    pages = {267--288},
    posted-at = {2010-05-26 10:32:01},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {{Regression Shrinkage and Selection via the Lasso}},
    url = {http://dx.doi.org/10.2307/2346178},
    volume = {58},
    year = {1996}
}

@article{derksen1992,
    abstract = {{The use of automated subset search algorithms is reviewed and issues concerning model selection and selection criteria are discussed. In addition, a Monte Carlo study is reported which presents data regarding the frequency with which authentic and noise variables are selected by automated subset algorithms. In particular, the effects of the correlation between predictor variables, the number of candidate predictor variables, the size of the sample, and the level of significance for entry and deletion of variables were studied for three automated subset algorithms: BACKWARD ELIMINATION, FORWARD SELECTION, and STEPWISE. Results indicated that: (1) the degree of correlation between the predictor variables affected the frequency with which authentic predictor variables found their way into the final model; (2) the number of candidate predictor variables affected the number of noise variables that gained entry to the model; (3) the size of the sample was of little practical importance in determining the number of authentic variables contained in the final model; and (4) the population multiple coefficient of determination could be faithfully estimated by adopting a statistic that is adjusted by the total number of candidate predictor variables rather than the number of variables in the final model.}},
    author = {Derksen, S. and Keselman, H. J.},
    citeulike-article-id = {9957707},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.2044-8317.1992.tb00992.x},
    day = {1},
    doi = {10.1111/j.2044-8317.1992.tb00992.x},
    issn = {00071102},
    journal = {British Journal of Mathematical and Statistical Psychology},
    keywords = {statistics, stepwise},
    month = nov,
    number = {2},
    pages = {265--282},
    posted-at = {2014-09-04 13:51:10},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {{Backward, forward and stepwise automated subset selection algorithms: Frequency of obtaining authentic and noise variables}},
    url = {http://dx.doi.org/10.1111/j.2044-8317.1992.tb00992.x},
    volume = {45},
    year = {1992}
}

@book{lutz2006,
  title={Programming Python},
  author={Lutz, M.},
  isbn={9780596554613},
  url={http://books.google.co.uk/books?id=tN7JAceyJdUC},
  year={2006},
  publisher={O'Reilly Media}
}

@book{machin2009,
    author = {Machin, D. and Campbell, M. J. and Tan, S-B. and Tan, S-H.},
    citeulike-article-id = {7084484},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1405146508},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1405146508},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1405146508},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1405146508},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1405146508/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1405146508},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1405146508},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1405146508},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1405146508\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1405146508},
    day = {15},
    edition = {3},
    howpublished = {Hardcover},
    isbn = {1405146508},
    keywords = {books, ctru, sample\_size\_determination, samplesize, statistics},
    month = dec,
    posted-at = {2010-04-26 13:02:13},
    priority = {2},
    publisher = {BMJ Books},
    title = {{Sample Size Tables for Clinical Studies}},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1405146508},
    year = {2009}
}

@article{steyerberg2001,
    abstract = {{Clinical decision making often requires estimates of the likelihood of a dichotomous outcome in individual patients. When empirical data are available, these estimates may well be obtained from a logistic regression model. Several strategies may be followed in the development of such a model. In this study, the authors compare alternative strategies in 23 small subsamples from a large data set of patients with an acute myocardial infarction, where they developed predictive models for 30-day mortality. Evaluations were performed in an independent part of the data set. Specifically, the authors studied the effect of coding of covariables and stepwise selection on discriminative ability of the resulting model, and the effect of statistical  ” shrinkage” techniques on calibration. As expected, dichotomization of continuous covariables implied a loss of information. Remarkably, stepwise selection resulted in less discriminating models compared to full models including all available covariables, even when more than half of these were randomly associated with the outcome. Using qualitative information on the sign of the effect of predictors slightly improved the predictive ability. Calibration improved when shrinkage was applied on the standard maximum likelihood estimates of the regression coefficients. In conclusion, a sensible strategy in small data sets is to apply shrinkage methods in full models that include well-coded predictors that are selected based on external information.}},
    author = {Steyerberg, E. W. and Eijkemans, M, J. C. and Harrell, F. E. and Habbema, J. D. F.},
    citeulike-article-id = {3753898},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0272989x0102100106},
    citeulike-linkout-1 = {http://mdm.sagepub.com/content/21/1/45.abstract},
    citeulike-linkout-2 = {http://mdm.sagepub.com/content/21/1/45.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/11206946},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=11206946},
    day = {01},
    doi = {10.1177/0272989x0102100106},
    issn = {1552-681X},
    journal = {Medical Decision Making},
    keywords = {modelling, regression, statistics},
    month = feb,
    number = {1},
    pages = {45--56},
    pmid = {11206946},
    posted-at = {2014-10-01 15:30:02},
    priority = {2},
    publisher = {SAGE Publications},
    title = {{Prognostic Modeling with Logistic Regression Analysis}},
    url = {http://dx.doi.org/10.1177/0272989x0102100106},
    volume = {21},
    year = {2001}
}

@article{steyerberg2001b,
    abstract = {{The performance of a predictive model is overestimated when simply determined on the sample of subjects that was used to construct the model. Several internal validation methods are available that aim to provide a more accurate estimate of model performance in new subjects. We evaluated several variants of split-sample, cross-validation and bootstrapping methods with a logistic regression model that included eight predictors for 30-day mortality after an acute myocardial infarction. Random samples with a size between n = 572 and n = 9165 were drawn from a large data set (GUSTO-I; n = 40,830; 2851 deaths) to reflect modeling in data sets with between 5 and 80 events per variable. Independent performance was determined on the remaining subjects. Performance measures included discriminative ability, calibration and overall accuracy. We found that split-sample analyses gave overly pessimistic estimates of performance, with large variability. Cross-validation on 10\% of the sample had low bias and low variability, but was not suitable for all performance measures. Internal validity could best be estimated with bootstrapping, which provided stable estimates with low bias. We conclude that split-sample validation is inefficient, and recommend bootstrapping for estimation of internal validity of a predictive logistic regression model.}},
    author = {Steyerberg, E. W. and Harrell, F. E. and Borsboom, G. J. and Eijkemans, M. J. and Vergouwe, Y. and Habbema, J. D.},
    citeulike-article-id = {3748536},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/11470385},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=11470385},
    issn = {0895-4356},
    journal = {Journal of clinical epidemiology},
    keywords = {dipep, prognostic\_model},
    month = aug,
    number = {8},
    pages = {774--781},
    pmid = {11470385},
    posted-at = {2016-02-03 11:31:37},
    priority = {2},
    title = {{Internal validation of predictive models: efficiency of some procedures for logistic regression analysis.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/11470385},
    volume = {54},
    year = {2001}
}


@article{massy1965,
    abstract = {{Regression upon principal components of the percentage points of the income and education distributions for 1950 census tracts in the city of Chicago led to the estimation of ?beta coefficient profiles? for television receiver and refrigerator ownership, for central heating system usage, and for a measure of dwelling unit overcrowding. The betas are standardized coefficients of regression of a dependent variable upon the proportions of families in the classes of the marginal income and education distributions. They measure the relative contribution of families in these classes to the over-all per cent saturation of the dependent variable in the tract. The coefficients were estimated by techniques developed in the first portion of the paper; estimation by classical regression methods would have been impossible because of multicollinearity. The empirical results are in substantial agreement with findings from regressions of the dependent variables upon the mean values of income and education, and their squares. The statistical devices appear to be useful in exploratory empirical research.}},
    author = {Massy, W. F.},
    citeulike-article-id = {13384028},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1965.10480787},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1965.10480787},
    day = {1},
    doi = {10.1080/01621459.1965.10480787},
    journal = {Journal of the American Statistical Association},
    keywords = {methodology, principal\_component\_analysis, regression, statistics},
    month = mar,
    number = {309},
    pages = {234--256},
    posted-at = {2014-10-06 12:37:34},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{Principal Components Regression in Exploratory Statistical Research}},
    url = {http://dx.doi.org/10.1080/01621459.1965.10480787},
    volume = {60},
    year = {1965}
}

@article{RCol-ObyGyn,
    abstract = {{}},
    author = {Royal College of Obstetricians and Gynaecologists},
    journal = {Green-top Guideline},
    number = {No 37b},
    volume = {No 37b},
    year = {2010}
}

@article{leung2012,
    abstract = {{Pulmonary embolism (PE) is a leading cause of maternal mortality in the developed world. Along with appropriate prophylaxis and therapy, prevention of death from PE in pregnancy requires a high index of clinical suspicion followed by a timely and accurate diagnostic approach. To provide guidance on this important health issue, a multidisciplinary panel of major medical stakeholders was convened to develop evidence-based guidelines for evaluation of suspected pulmonary embolism in pregnancy using the Grades of Recommendation, Assessment, Development, and Evaluation (GRADE) system. In formulation of the recommended diagnostic algorithm, the important outcomes were defined to be diagnostic accuracy and diagnostic yield; the panel placed a high value on minimizing cumulative radiation dose when determining the recommended sequence of tests. Overall, the quality of the underlying evidence for all recommendations was rated as very low or low with some of the evidence considered for recommendations extrapolated from studies of the general population. Despite the low quality evidence, strong recommendations were made for three specific scenarios: performance of chest radiography (CXR) as the first radiation-associated procedure; use of lung scintigraphy as the preferred test in the setting of a normal CXR; and performance of computed-tomographic pulmonary angiography (CTPA) rather than digital subtraction angiography (DSA) in a pregnant woman with a nondiagnostic ventilation-perfusion (V/Q) result. The recommendations presented in this guideline are based upon the currently available evidence; availability of new clinical research data and development and dissemination of new technologies will necessitate a revision and update. {\copyright} RSNA, 2011}},
    author = {Leung, Ann N. and Bull, Todd M. and Jaeschke, Roman and Lockwood, Charles J. and Boiselle, Phillip M. and Hurwitz, Lynne M. and James, Andra H. and McCullough, Laurence B. and Menda, Yusuf and Paidas, Michael J. and Royal, Henry D. and Tapson, Victor F. and Winer-Muram, Helen T. and Chervenak, Frank A. and Cody, Dianna D. and McNitt-Gray, Michael F. and Stave, Christopher D. and Tuttle, Brandi D. and {ATS/STR Committee on Pulmonary Embolism in Pregnancy}},
    citeulike-article-id = {10425615},
    citeulike-linkout-0 = {http://dx.doi.org/10.1148/radiol.11114045},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/22282185},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=22282185},
    doi = {10.1148/radiol.11114045},
    issn = {1527-1315},
    journal = {Radiology},
    keywords = {dipep},
    month = feb,
    number = {2},
    pages = {635--646},
    pmid = {22282185},
    posted-at = {2014-10-07 10:45:28},
    priority = {2},
    title = {{American Thoracic Society documents: an official American Thoracic Society/Society of Thoracic Radiology Clinical Practice Guideline--Evaluation of Suspected Pulmonary Embolism in Pregnancy.}},
    url = {http://dx.doi.org/10.1148/radiol.11114045},
    volume = {262},
    year = {2012}
}


@article{strobl2009,
    abstract = {{Recursive partitioning methods have become popular and widely used tools for nonparametric regression and classification in many scientific fields. Especially random forests, which can deal with large numbers of predictor variables even in the presence of complex interactions, have been applied successfully in genetics, clinical medicine, and bioinformatics within the past few years. High-dimensional problems are common not only in genetics, but also in some areas of psychological research, where only a few subjects can be measured because of time or cost constraints, yet a large amount of data is generated for each subject. Random forests have been shown to achieve a high prediction accuracy in such applications and to provide descriptive variable importance measures reflecting the impact of each variable in both main effects and interactions. The aim of this work is to introduce the principles of the standard recursive partitioning methods as well as recent methodological improvements, to illustrate their usage for low and high-dimensional data exploration, but also to point out limitations of the methods and potential pitfalls in their practical application. Application of the methods is illustrated with freely available implementations in the R system for statistical computing. (c) 2009 APA, all rights reserved.}},
    author = {Strobl, C. and Malley, J. and Tutz, G.},
    citeulike-article-id = {8189344},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0016973},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2927982/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19968396},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19968396},
    doi = {10.1037/a0016973},
    issn = {1939-1463},
    journal = {Psychological methods},
    keywords = {recurrsive\_partitioning, statistics},
    month = dec,
    number = {4},
    pages = {323--348},
    pmcid = {PMC2927982},
    pmid = {19968396},
    posted-at = {2014-10-16 17:42:05},
    priority = {2},
    title = {{An introduction to recursive partitioning: rationale, application, and characteristics of classification and regression trees, bagging, and random forests.}},
    url = {http://dx.doi.org/10.1037/a0016973},
    volume = {14},
    year = {2009}
}

@book{james2013,
    author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
    citeulike-article-id = {12889876},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1461471370},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1461471370},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1461471370},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1461471370},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1461471370/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1461471370},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1461471370},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1461471370},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1461471370\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1461471370},
    day = {12},
    edition = {1st ed. 2013. Corr. 4th printing 2014},
    howpublished = {Hardcover},
    isbn = {1461471370},
    keywords = {books, statistics},
    month = aug,
    posted-at = {2014-10-17 10:00:28},
    priority = {2},
    publisher = {Springer},
    title = {{An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics)}},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1461471370},
    year = {2013}
}

@book{hastie2003,
    abstract = {{During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book descibes theimprtant ideas in these areas ina common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a vluable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learing (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit.}},
    author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
    booktitle = {The Elements of Statistical Learning},
    citeulike-article-id = {161814},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387952845},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387952845},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387952845},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387952845},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387952845/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387952845},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387952845},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387952845},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387952845\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387952845},
    day = {30},
    edition = {Corrected},
    howpublished = {Hardcover},
    isbn = {0387952845},
    keywords = {book, statistics},
    month = aug,
    posted-at = {2014-10-17 09:49:09},
    priority = {2},
    publisher = {Springer},
    title = {{The Elements of Statistical Learning: Data Mining, Inference, and Prediction}},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387952845},
    year = {2003}
}

@article{hosmer1980,
    abstract = {{Several test statistics are proposed for the purpose of assessing the goodness of fit of the multiple logistic regression model. The test statistics are obtained by applying a chi-square test for a contingency table in which the expected frequencies are determined using two different grouping strategies and two different sets of distributional assumptions. The null distributions of these statistics are examined by applying the theory for chi-square tests of Moore Spruill (1975) and through computer simulations. All statistics are shown to have a chi-square distribution or a distribution which can be well approximated by a chi-square. The degrees of freedom are shown to depend on the particular statistic and the distributional assumptions. The power of each of the proposed statistics is examined for the normal, linear, and exponential alternative models using computer simulations.}},
    author = {Hosmer, D. W. and Lemesbow, S.},
    citeulike-article-id = {9011509},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/03610928008827941},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/03610928008827941},
    day = {1},
    doi = {10.1080/03610928008827941},
    journal = {Communications in Statistics - Theory and Methods},
    keywords = {fit, logistic, modelling, regression},
    month = jan,
    number = {10},
    pages = {1043--1069},
    posted-at = {2013-10-21 16:03:57},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{Goodness of fit tests for the multiple logistic regression model}},
    url = {http://dx.doi.org/10.1080/03610928008827941},
    volume = {9},
    year = {1980}
}

@article{hosmer1997,
    abstract = {{Recent work has shown that there may be disadvantages in the use of the chi-square-like goodness-of-fit tests for the logistic regression model proposed by Hosmer and Lemeshow that use fixed groups of the estimated probabilities. A particular concern with these grouping strategies based on estimated probabilities, fitted values, is that groups may contain subjects with widely different values of the covariates. It is possible to demonstrate situations where one set of fixed groups shows the model fits while the test rejects fit using a different set of fixed groups. We compare the performance by simulation of these tests to tests based on smoothed residuals proposed by le Cessie and Van Houwelingen and Royston, a score test for an extended logistic regression model proposed by Stukel, the Pearson chi-square and the unweighted residual sum-of-squares. These simulations demonstrate that all but one of Royston's tests have the correct size. An examination of the performance of the tests when the correct model has a quadratic term but a model containing only the linear term has been fit shows that the Pearson chi-square, the unweighted sum-of-squares, the Hosmer-Lemeshow decile of risk, the smoothed residual sum-of-squares and Stukel's score test, have power exceeding 50 per cent to detect moderate departures from linearity when the sample size is 100 and have power over 90 per cent for these same alternatives for samples of size 500. All tests had no power when the correct model had an interaction between a dichotomous and continuous covariate but only the continuous covariate model was fit. Power to detect an incorrectly specified link was poor for samples of size 100. For samples of size 500 Stukel's score test had the best power but it only exceeded 50 per cent to detect an asymmetric link function. The power of the unweighted sum-of-squares test to detect an incorrectly specified link function was slightly less than Stukel's score test. We illustrate the tests within the context of a model for factors associated with low birth weight.}},
    author = {Hosmer, D. W. and Hosmer, T. and Le Cessie, S. and Lemeshow, S.},
    citeulike-article-id = {9960110},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/9160492},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=9160492},
    day = {15},
    issn = {0277-6715},
    journal = {Statistics in medicine},
    keywords = {goodnessoffit, staistics},
    month = may,
    number = {9},
    pages = {965--980},
    pmid = {9160492},
    posted-at = {2013-09-06 11:05:15},
    priority = {2},
    title = {{A comparison of goodness-of-fit tests for the logistic regression model.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/9160492},
    volume = {16},
    year = {1997}
}

@article{calster2014,
    abstract = {{When comparing prediction models, it is essential to estimate the magnitude of change in performance rather than rely solely on statistical significance. In this paper we investigate measures that estimate change in classification performance, assuming 2-group classification based on a single risk threshold. We study the value of a new biomarker when added to a baseline risk prediction model. First, simulated data are used to investigate the change in sensitivity and specificity (ΔSe and ΔSp). Second, the influence of ΔSe and ΔSp on the net reclassification improvement (NRI; sum of ΔSe and ΔSp) and on decision-analytic measures (net benefit or relative utility) is studied. We assume normal distributions for the predictors and assume correctly specified models such that the extended model has a dominating receiver operating characteristic curve relative to the baseline model. Remarkably, we observe that even when a strong marker is added it is possible that either sensitivity (for thresholds below the event rate) or specificity (for thresholds above the event rate) decreases. In these cases, decision-analytic measures provide more modest support for improved classification than NRI, even though all measures confirm that adding the marker improved classification accuracy. Our results underscore the necessity of reporting ΔSe and ΔSp separately. When a single summary is desired, decision-analytic measures allow for a simple incorporation of the misclassification costs.}},
    author = {Van Calster, Ben and Steyerberg, Ewout W. and D'Agostino, Ralph B. and Pencina, Michael J.},
    citeulike-article-id = {13244775},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/24378915},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=24378915},
    issn = {1552-681X},
    journal = {Medical decision making : an international journal of the Society for Medical Decision Making},
    keywords = {dipep, sensitivity, specificity, statistics},
    month = may,
    number = {4},
    pages = {513--522},
    pmid = {24378915},
    posted-at = {2015-02-18 09:08:41},
    priority = {2},
    title = {{Sensitivity and specificity can change in opposite directions when new predictive markers are added to risk models.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/24378915},
    volume = {34},
    year = {2014}
}

@article{oconnor2011,
    abstract = {{Objective: To examine the use of the modified Wells score in pregnancy as a risk stratification tool in the diagnosis of pulmonary embolism (PE). Methods: All pregnant or post-partum patients who were referred for CT Pulmonary Angiography (CTPA) to evaluate suspected PE over a 5-year period were included in the study. Patient records were used to apply the modified Wells score (MWS) and analyze their risk of PE. Results: A total of 125 women were referred for CTPA over 5 years. A MWS of 6 or greater (?High Risk?) was 100\% sensitive and 90\% specific with a positive predictive value of 36\% for PE on CTPA. No patients with a low MWS (less than 6) had a PE, giving a negative predictive value of 100\%. p?≤?0.001. D-dimers, chest X-ray, blood gases and EKG were significantly less effective than the MWS in aiding the diagnosis of PE. Conclusion: Current methods employed for the diagnosis of PE are inadequate. Risk stratification using the MWS may allow safe exclusion of PE before resorting to CTPA. To the best of our knowledge this is the first study to have used the MWS in a pregnant patient group.}},
    author = {O'Connor, Clare and Moriarty, John and Walsh, Jennifer and Murray, John and Coulter-Smith, Sam and Boyd, William},
    citeulike-article-id = {13764600},
    citeulike-linkout-0 = {http://dx.doi.org/10.3109/14767058.2011.614652},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.3109/14767058.2011.614652},
    day = {19},
    doi = {10.3109/14767058.2011.614652},
    journal = {The Journal of Maternal-Fetal \& Neonatal Medicine},
    keywords = {dipep},
    month = aug,
    number = {12},
    pages = {1461--1464},
    posted-at = {2015-09-15 17:33:51},
    priority = {2},
    publisher = {Taylor \& Francis},
    title = {{The application of a clinical risk stratification score may reduce unnecessary investigations for pulmonary embolism in pregnancy}},
    url = {http://dx.doi.org/10.3109/14767058.2011.614652},
    volume = {24},
    year = {2011}
}

@article{kline2004,
    abstract = {{Overuse of the d-dimer to screen for possible pulmonary embolism (PE) can have negative consequences. This study derives and tests clinical criteria to justify not ordering a d-dimer. The test threshold was estimated at 1.8\% using the method of Pauker and Kassirer. The PE rule-out criteria were derived from logistic regression analysis with stepwise backward elimination of 21 variables collected on 3148 emergency department patients evaluated for PE at 10 US hospitals. Eight variables were included in a block rule: Age < 50 years, pulse < 100 bpm, SaO(2) > 94\%, no unilateral leg swelling, no hemoptysis, no recent trauma or surgery, no prior PE or DVT, no hormone use. The rule was then prospectively tested in a low-risk group (1427 patients from two hospitals initially tested for PE with a d-dimer) and a very low-risk group (convenience sample of 382 patients with chief complaint of dyspnea, PE not suspected). The prevalence of PE was 8\% (95\% confidence interval: 7-9\%) in the low-risk group and 2\% (1-4\%) in the very low-risk group on longitudinal follow-up. Application of the rule in the low-risk and very low-risk populations yielded sensitivities of 96\% and 100\% and specificities of 27\% and 15\%, respectively. The prevalence of PE in those who met the rule criteria was 1.4\% (0.5-3.0\%) and 0\% (0-6.2\%), respectively. The derived eight-factor block rule reduced the pretest probability below the test threshold for d-dimer in two validation populations, but the rule's utility was limited by low specificity.}},
    author = {Kline, J. A. and Mitchell, A. M. and Kabrhel, C. and Richman, P. B. and Courtney, D. M.},
    citeulike-article-id = {13764598},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/15304025},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=15304025},
    issn = {1538-7933},
    journal = {Journal of thrombosis and haemostasis : JTH},
    keywords = {dipep},
    month = aug,
    number = {8},
    pages = {1247--1255},
    pmid = {15304025},
    posted-at = {2015-09-15 17:32:48},
    priority = {2},
    title = {{Clinical criteria to prevent unnecessary diagnostic testing in emergency department patients with suspected pulmonary embolism.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/15304025},
    volume = {2},
    year = {2004}
}

@article{wells2001,
    abstract = {{The limitations of the current diagnostic standard, ventilation-perfusion lung scanning, complicate the management of patients with suspected pulmonary embolism. We previously demonstrated that determining the pretest probability can assist with management and that the high negative predictive value of certain D -dimer assays may simplify the diagnostic process. To determine the safety of using a simple clinical model combined with D -dimer assay to manage patients presenting to the emergency department with suspected pulmonary embolism. Prospective cohort study. Emergency departments at four tertiary care hospitals in Canada. 930 consecutive patients with suspected pulmonary embolism. Physicians first used a clinical model to determine patients' pretest probability of pulmonary embolism and then performed a D -dimer test. Patients with low pretest probability and a negative D -dimer result had no further tests and were considered to have a diagnosis of pulmonary embolism excluded. All other patients underwent ventilation-perfusion lung scanning. If the scan was nondiagnostic, bilateral deep venous ultrasonography was done. Whether further testing (by serial ultrasonography or angiography) was done depended on the patients' pretest probability and the lung scanning results. Patients received a diagnosis of pulmonary embolism if they had a high-probability ventilation-perfusion scan, an abnormal result on ultrasonography or pulmonary angiography, or a venous thromboembolic event during follow-up. Patients for whom the diagnosis was considered excluded were followed up for 3 months for the development of thromboembolic events. The pretest probability of pulmonary embolism was low, moderate, and high in 527, 339, and 64 patients (1.3\%, 16.2\%, and 37.5\% had pulmonary embolism), respectively. Of 849 patients in whom a diagnosis of pulmonary-embolism had initially been excluded, 5 (0.6\% [95\% CI, 0.2\% to 1.4\%]) developed pulmonary embolism or deep venous thrombosis during follow-up. However, 4 of these patients had not undergone the proper diagnostic testing protocol. In 7 of the patients who received a diagnosis of pulmonary embolism, the physician had performed more diagnostic tests than were called for by the algorithm. In 759 of the 849 patients in whom pulmonary embolism was not found on initial evaluation, the diagnostic protocol was followed correctly. Only 1 (0.1\% [CI, 0.0\% to 0.7\%]) of these 759 patients developed thromboembolic events during follow-up. Of the 437 patients with a negative D -dimer result and low clinical probability, only 1 developed pulmonary embolism during follow-up; thus, the negative predictive value for the combined strategy of using the clinical model with D -dimer testing in these patients was 99.5\% (CI, 99.1\% to 100\%). Managing patients for suspected pulmonary embolism on the basis of pretest probability and D -dimer result is safe and decreases the need for diagnostic imaging.}},
    author = {Wells, P. S. and Anderson, D. R. and Rodger, M. and Stiell, I. and Dreyer, J. F. and Barnes, D. and Forgie, M. and Kovacs, G. and Ward, J. and Kovacs, M. J.},
    citeulike-article-id = {6652651},
    citeulike-linkout-0 = {http://www.annals.org/content/135/2/98.abstract},
    citeulike-linkout-1 = {http://www.annals.org/content/135/2/98.full.pdf},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/11453709},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=11453709},
    day = {17},
    issn = {0003-4819},
    journal = {Annals of internal medicine},
    keywords = {dipep},
    month = jul,
    number = {2},
    pages = {98--107},
    pmid = {11453709},
    posted-at = {2015-09-15 17:31:25},
    priority = {2},
    title = {{Excluding pulmonary embolism at the bedside without diagnostic imaging: management of patients with suspected pulmonary embolism presenting to the emergency department by using a simple clinical model and d-dimer.}},
    url = {http://www.annals.org/content/135/2/98.abstract},
    volume = {135},
    year = {2001}
}

@article{cutts2014,
    author = {Cutts, Briony A. and Tran, Huyen A. and Merriman, Eileen and Nandurkar, Dee and Soo, Gil and DasGupta, Dhruba and Prassannan, Nita and Hunt, Beverley J.},
    citeulike-article-id = {13764611},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/mbc.0000000000000054},
    doi = {10.1097/mbc.0000000000000054},
    issn = {0957-5235},
    journal = {Blood Coagulation \& Fibrinolysis},
    keywords = {dipep},
    month = jun,
    number = {4},
    pages = {375--378},
    posted-at = {2015-09-15 17:46:52},
    priority = {2},
    title = {{The utility of the Wells clinical prediction model and ventilation-perfusion scanning for pulmonary embolism diagnosis in pregnancy}},
    url = {http://dx.doi.org/10.1097/mbc.0000000000000054},
    volume = {25},
    year = {2014}
}

@article{wicki2001,
  title={Assessing clinical probability of pulmonary embolism in the emergency ward: a simple score},
  author={Wicki, Jacques and Perneger, Thomas V and Junod, Alain F and Bounameaux, Henri and Perrier, Arnaud},
  journal={Archives of Internal Medicine},
  volume={161},
  number={1},
  pages={92--97},
  year={2001},
  publisher={American Medical Association}
}

@article{klok2008,
  title={Simplification of the revised Geneva score for assessing clinical probability of pulmonary embolism},
  author={Klok, Frederikus A and Mos, Inge CM and Nijkeuter, Mathilde and Righini, Marc and Perrier, Arnaud and Le Gal, Gr{\'e}goire and Huisman, Menno V},
  citeulike-linkout-0 = {https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/414578},
  journal={Archives of Internal Medicine},
  volume={168},
  number={19},
  pages={2131--2136},
  year={2008},
  publisher={American Medical Association}
}

@article{spiegelhalter1986,
    abstract = {{It is argued that the provision of accurate and useful probabilistic assessments of future events should be a fundamental task for biostatisticians collaborating in clinical or experimental medicine, and we explore two aspects of obtaining and evaluating such predictions. When covariate information on patients is available, logistic regression and other multivariate techniques are often used to select prognostic factors and create predictive models. An example shows how the explicit aim of prediction needs to be taken into account in such modelling, and how predictive performance may be assessed by decomposition of a scoring rule. Secondly, results from a program that provides pretrial and interim predictions in clinical trials are displayed, bringing together the use of subjective opinion, Bayesian methodology and techniques for evaluating and criticizing predictions.}},
    author = {Spiegelhalter, D. J.},
    citeulike-article-id = {13924619},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/3786996},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=3786996},
    issn = {0277-6715},
    journal = {Statistics in medicine},
    keywords = {dipep, prognostic\_model, scharr},
    number = {5},
    pages = {421--433},
    pmid = {3786996},
    posted-at = {2016-02-03 12:51:36},
    priority = {2},
    title = {{Probabilistic prediction in patient management and clinical trials.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/3786996},
    volume = {5},
    year = {1986}
}

@Manual{rpart.plotpackage,
    author = {Stephen Milborrow},
    title = {{rpart.plot: Plot rpart Models. An Enhanced Version of plot.rpart}},
    year = {2016},
    note = {R package},
    url = {http://CRAN.R-project.org/package=rpart.plot }
}

@article{pencina2008,
    abstract = {{Identification of key factors associated with the risk of developing cardiovascular disease and quantification of this risk using multivariable prediction algorithms are among the major advances made in preventive cardiology and cardiovascular epidemiology in the 20th century. The ongoing discovery of new risk markers by scientists presents opportunities and challenges for statisticians and clinicians to evaluate these biomarkers and to develop new risk formulations that incorporate them. One of the key questions is how best to assess and quantify the improvement in risk prediction offered by these new models. Demonstration of a statistically significant association of a new biomarker with cardiovascular risk is not enough. Some researchers have advanced that the improvement in the area under the receiver-operating-characteristic curve (AUC) should be the main criterion, whereas others argue that better measures of performance of prediction models are needed. In this paper, we address this question by introducing two new measures, one based on integrated sensitivity and specificity and the other on reclassification tables. These new measures offer incremental information over the AUC. We discuss the properties of these new measures and contrast them with the AUC. We also develop simple asymptotic tests of significance. We illustrate the use of these measures with an example from the Framingham Heart Study. We propose that scientists consider these types of measures in addition to the AUC when assessing the performance of newer biomarkers. Copyright {\copyright} 2007 John Wiley \& Sons, Ltd.}},
    author = {Pencina, Michael J. and D' Agostino, Ralph B. and D' Agostino, Ralph B. and Vasan, Ramachandran S.},
    citeulike-article-id = {2869909},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2929},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/17569110},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=17569110},
    citeulike-linkout-3 = {http://www3.interscience.wiley.com/cgi-bin/abstract/114278764/ABSTRACT},
    day = {30},
    doi = {10.1002/sim.2929},
    issn = {0277-6715},
    journal = {Statist. Med.},
    keywords = {classification, roc, statistics},
    month = jan,
    number = {2},
    pages = {157--172},
    pmid = {17569110},
    posted-at = {2016-10-31 13:32:06},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {{Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond}},
    url = {http://dx.doi.org/10.1002/sim.2929},
    volume = {27},
    year = {2008}
}

@article{hapfelmeier2012,
    abstract = {{The occurrence of missing data is a major problem in statistical data analysis. All scientific fields and data of all kinds and size are touched by this problem. There is a number of ad-hoc solutions which unfortunately lead to a loss of power, biased inference, underestimation of variability and distorted relationships between variables. A more promising approach of rising popularity is multiple imputation by chained equations (MICE) also known as imputation by full conditional specification (FCS). Alternatives to imputation are given by methods with built-in procedures. These include recursive partitioning by classification and regression trees as well as corresponding Random Forests. However there is only few literature comparing the two approaches. Existing evaluations often lack generalizability due to restrictions on data structure and simulation schemes. The application of both methods to several kinds of data and different simulation settings is meant to improve and extend the comparative analyses. Classification and regression studies are examined. Recursive partitioning is executed by two popular tree and one Random Forest implementation. Findings show that multiple imputation produces ambiguous performance results for both, simulated and real life data. Using surrogates instead is a fast and simple way to achieve performances which are only negligible worse and in many cases even superior.}},
    author = {Hapfelmeier, A. and Hothorn, T. and Ulm, K.},
    citeulike-article-id = {9868428},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.csda.2011.09.024},
    doi = {10.1016/j.csda.2011.09.024},
    issn = {01679473},
    journal = {Computational Statistics \& Data Analysis},
    keywords = {dipep},
    month = jun,
    number = {6},
    pages = {1552--1565},
    posted-at = {2016-11-22 16:26:25},
    priority = {2},
    title = {{Recursive partitioning on incomplete data using surrogate decisions and multiple imputation}},
    url = {http://dx.doi.org/10.1016/j.csda.2011.09.024},
    volume = {56},
    year = {2012}
}

@article{friedman2010,
    abstract = {{We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multinomial regression problems while the penalties include ℓ(1) (the lasso), ℓ(2) (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.}},
    author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
    citeulike-article-id = {8316221},
    citeulike-linkout-0 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2929880/},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/20808728},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=20808728},
    issn = {1548-7660},
    journal = {Journal of statistical software},
    keywords = {lasso, statistics},
    number = {1},
    pages = {1--22},
    pmcid = {PMC2929880},
    pmid = {20808728},
    posted-at = {2017-01-10 15:53:09},
    priority = {2},
    title = {{Regularization Paths for Generalized Linear Models via Coordinate Descent.}},
    url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2929880/},
    volume = {33},
    year = {2010}
}

@article{spiegelhalter1986,
    abstract = {{It is argued that the provision of accurate and useful probabilistic assessments of future events should be a fundamental task for biostatisticians collaborating in clinical or experimental medicine, and we explore two aspects of obtaining and evaluating such predictions. When covariate information on patients is available, logistic regression and other multivariate techniques are often used to select prognostic factors and create predictive models. An example shows how the explicit aim of prediction needs to be taken into account in such modelling, and how predictive performance may be assessed by decomposition of a scoring rule. Secondly, results from a program that provides pretrial and interim predictions in clinical trials are displayed, bringing together the use of subjective opinion, Bayesian methodology and techniques for evaluating and criticizing predictions.}},
    author = {Spiegelhalter, D. J.},
    citeulike-article-id = {14256340},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780050506},
    day = {1},
    doi = {10.1002/sim.4780050506},
    journal = {Statist. Med.},
    keywords = {prediction, statistics},
    month = sep,
    number = {5},
    pages = {421--433},
    posted-at = {2017-01-17 17:06:20},
    priority = {2},
    publisher = {Wiley Subscription Services, Inc., A Wiley Company},
    title = {{Probabilistic prediction in patient management and clinical trials}},
    url = {http://dx.doi.org/10.1002/sim.4780050506},
    volume = {5},
    year = {1986}
}

@article{heavner2010,
    abstract = {{Consumers of epidemiology may prefer to have one measure of risk arising from analysis of a 2-by-2 table. However, reporting a single measure of association, such as one odds ratio (OR) and 95\% confidence interval, from a continuous exposure variable that was dichotomized withholds much potentially useful information. Results of this type of analysis are often reported for one such dichotomization, as if no other cutoffs were investigated or even possible. This analysis demonstrates the effect of using different theory and data driven cutoffs on the relationship between body mass index and high cholesterol using National Health and Nutrition Examination Survey data. The recommended analytic approach, presentation of a graph of ORs for a range of cutoffs, is the focus of most of the results and discussion. These cutoff variations resulted in ORs between 1.1 and 1.9. This allows investigators to select a result that either strongly supports or provides negligible support for an association; a choice that is invisible to readers. The OR curve presents readers with more information about the exposure disease relationship than a single OR and 95\% confidence interval. As well as offering results for additional cutoffs that may be of interest to readers, the OR curve provides an indication of whether the study focuses on a reasonable representation of the data or outlier results. It offers more information about trends in the association as the cutoff changes and the implications of random fluctuations than a single OR and 95\% confidence interval.}},
    author = {Heavner, Karyn K. and Phillips, Carl V. and Burstyn, Igor and Hare, Warren},
    citeulike-article-id = {7372483},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2288-10-59},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2902492/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/20573189},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=20573189},
    doi = {10.1186/1471-2288-10-59},
    issn = {1471-2288},
    journal = {BMC medical research methodology},
    keywords = {cut-points, cutoffs, dichotomization, methodology, statistics},
    number = {1},
    pages = {59+},
    pmcid = {PMC2902492},
    pmid = {20573189},
    posted-at = {2010-07-01 12:36:04},
    priority = {2},
    title = {{Dichotomization: 2 x 2 (x2 x 2 x 2...) categories: infinite possibilities.}},
    url = {http://dx.doi.org/10.1186/1471-2288-10-59},
    volume = {10},
    year = {2010}
}

@article{royston2006,
    abstract = {{In medical research, continuous variables are often converted into categorical variables by grouping values into two or more categories. We consider in detail issues pertaining to creating just two groups, a common approach in clinical research. We argue that the simplicity achieved is gained at a cost; dichotomization may create rather than avoid problems, notably a considerable loss of power and residual confounding. In addition, the use of a data-derived 'optimal' cutpoint leads to serious bias. We illustrate the impact of dichotomization of continuous predictor variables using as a detailed case study a randomized trial in primary biliary cirrhosis. Dichotomization of continuous data is unnecessary for statistical analysis and in particular should not be applied to explanatory variables in regression models. Copyright 2005 John Wiley \& Sons, Ltd.}},
    address = {MRC Clinical Trials Unit, 222 Euston Road, London NW1 2DA, U.K.; Centre for Statistics in Medicine, University of Oxford, Wolfson College Annexe, Linton Road, Oxford OX2 6UD, U.K.; Institute of Medical Biometry and Medical Informatics, University Hospital of Freiburg, Stefan-Meier-Str. 25, 79104 Freiburg, Germany},
    author = {Royston, Patrick and Altman, Douglas G. and Sauerbrei, Willi},
    citeulike-article-id = {1033459},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2331},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16217841},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16217841},
    citeulike-linkout-3 = {http://www3.interscience.wiley.com/cgi-bin/abstract/112099927/ABSTRACT},
    day = {15},
    doi = {10.1002/sim.2331},
    issn = {0277-6715},
    journal = {Statistics in medicine},
    keywords = {dichotomization, methodology, regression, statistics},
    month = jan,
    number = {1},
    pages = {127--141},
    pmid = {16217841},
    posted-at = {2011-04-21 13:54:15},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {{Dichotomizing continuous predictors in multiple regression: a bad idea.}},
    url = {http://dx.doi.org/10.1002/sim.2331},
    volume = {25},
    year = {2006}
}

@article{dawson2012,
    author = {Dawson, Neal V. and Weiss, Robert},
    citeulike-article-id = {10569516},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0272989x12437605},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/22457338},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=22457338},
    doi = {10.1177/0272989x12437605},
    issn = {1552-681X},
    journal = {Medical decision making : an international journal of the Society for Medical Decision Making},
    keywords = {dichotomization, statistics},
    month = mar,
    number = {2},
    pages = {225--226},
    pmid = {22457338},
    posted-at = {2017-02-22 11:40:52},
    priority = {2},
    title = {{Dichotomizing continuous variables in statistical analysis: a practice to avoid.}},
    url = {http://dx.doi.org/10.1177/0272989x12437605},
    volume = {32},
    year = {2012}
}

@article{altman2006,
    abstract = {{Footnotes Competing interests None declared.}},
    address = {Cancer Research UK/NHS Centre for Statistics in Medicine, Wolfson College, Oxford OX2 6UD. doug.altman@cancer.org.uk},
    author = {Altman, Douglas G. and Royston, Patrick},
    citeulike-article-id = {1529746},
    citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.332.7549.1080},
    citeulike-linkout-1 = {http://www.bmj.com/content/332/7549/1080.1.pdf+html.abstract},
    citeulike-linkout-2 = {http://www.bmj.com/content/332/7549/1080.1.pdf+html.full.pdf},
    citeulike-linkout-3 = {http://www.bmj.com/cgi/content/abstract/332/7549/1080},
    citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458573/},
    citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/16675816},
    citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=16675816},
    day = {04},
    doi = {10.1136/bmj.332.7549.1080},
    issn = {1468-5833},
    journal = {BMJ},
    keywords = {dichotomization, statistics},
    month = may,
    number = {7549},
    pages = {1080+},
    pmcid = {PMC1458573},
    pmid = {16675816},
    posted-at = {2017-02-22 11:40:24},
    priority = {2},
    publisher = {British Medical Journal Publishing Group},
    title = {{The cost of dichotomising continuous variables}},
    url = {http://dx.doi.org/10.1136/bmj.332.7549.1080},
    volume = {332},
    year = {2006}
}
